{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2021/blob/master/12-vae/MLDM_2021_seminar12_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "vQ9-baVWlRVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtR3OYQSs6MC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EY64ZjVtb_Q"
      },
      "outputs": [],
      "source": [
        "lfw = tfds.image_classification.LFW()\n",
        "lfw.download_and_prepare()\n",
        "ds = lfw.as_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVzsU0rotPSK"
      },
      "outputs": [],
      "source": [
        "def get_img(x):\n",
        "  return x['image'][80:-80,80:-80]\n",
        "\n",
        "data = np.array([\n",
        "  np.array(Image.fromarray(img.numpy()).resize((36, 36)))\n",
        "  for img in tqdm(ds['train'].map(get_img))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9p3GwjbtWxr"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz8KQmNDumG7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6NuBd7cunql"
      },
      "outputs": [],
      "source": [
        "plt.imshow(data[:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLbXtftPxEC5"
      },
      "outputs": [],
      "source": [
        "# dgts = False\n",
        "# X_train = data.astype('float32') / 255\n",
        "# print(X_train.min(), X_train.max(), X_train.dtype)\n",
        "# image_size = 36\n",
        "# n_channels = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to perform the visualization we'd better use MNIST dataset, however you may pick any data you prefer."
      ],
      "metadata": {
        "id": "WcUCCiC19P43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dgts = True\n",
        "(x_train, y_train), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "X_train = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "image_size = 28\n",
        "n_channels = 1"
      ],
      "metadata": {
        "id": "z7b6jZcTMoqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE"
      ],
      "metadata": {
        "id": "g7Mt454ClUhn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_kNbCPnwjh8"
      },
      "outputs": [],
      "source": [
        "ll = tf.keras.layers\n",
        "\n",
        "LATENT_DIM = 2 if dgts else 32 \n",
        "\n",
        "decoder = tf.keras.Sequential([\n",
        "  ll.Dense(128, input_shape=(LATENT_DIM,), activation='relu'),\n",
        "  ll.Dense(128, activation='relu'),\n",
        "  ll.Dense(image_size * image_size * n_channels, activation='sigmoid'),\n",
        "  ll.Reshape((image_size, image_size, n_channels)),\n",
        "])\n",
        "\n",
        "encoder_base = tf.keras.Sequential([\n",
        "  ll.Reshape((image_size * image_size * n_channels,), input_shape=(image_size, image_size, n_channels)),\n",
        "  ll.Dense(128, activation='relu'),\n",
        "  ll.Dense(128, activation='relu')\n",
        "])\n",
        "latent_mu = ll.Dense(LATENT_DIM, activation=None)(encoder_base.output)\n",
        "latent_logsigma = ll.Dense(LATENT_DIM, activation=None)(encoder_base.output)\n",
        "encoder = tf.keras.Model(inputs=encoder_base.inputs, outputs=[latent_mu, latent_logsigma])\n",
        "\n",
        "decoder.summary()\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gxjEFhdx886"
      },
      "outputs": [],
      "source": [
        "def gen_images(mu, logsigma):\n",
        "  return decoder(tf.random.normal(shape=mu.shape) * tf.exp(logsigma) + mu)\n",
        "\n",
        "# @tf.function decorator below compiles the function\n",
        "# it decorates into a static graph. This improves the performance\n",
        "# but there are some pitfalls one should be aware of when using it,\n",
        "# check out https://www.tensorflow.org/guide/function\n",
        "# for more details\n",
        "@tf.function\n",
        "def forward(batch):\n",
        "  real = batch\n",
        "\n",
        "  mu, logsigma = encoder(real)\n",
        "  fake = gen_images(mu, logsigma)\n",
        "\n",
        "  loss_mse = tf.reduce_sum((real - fake)**2, axis=(1, 2, 3))\n",
        "  loss_KL = tf.reduce_sum(-logsigma + 0.5 * (mu**2 + tf.exp(2 * logsigma) - 1), axis=1)\n",
        "  return tf.reduce_mean(loss_mse + 0.3 * loss_KL)\n",
        "\n",
        "opt_g = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def gen_step(batch):\n",
        "  with tf.GradientTape() as t:\n",
        "    g_loss = forward(batch)\n",
        "  grads = t.gradient(g_loss, encoder.trainable_variables + decoder.trainable_variables)\n",
        "  opt_g.apply_gradients(zip(grads, encoder.trainable_variables + decoder.trainable_variables))\n",
        "  return g_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQKnxL0M0DfI"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_mn(images, m=5, n=5, shuffle=False):\n",
        "    if shuffle:\n",
        "        images = images[np.random.permutation(len(images))[:m * n]]\n",
        "    _, h, w, _ = images.shape\n",
        "    images = images[:m*n].reshape(m, n, *images.shape[1:])\n",
        "    images = images.transpose(0, 2, 1, 3, 4).reshape(m * h, n * w)\n",
        "    plt.imshow(images)"
      ],
      "metadata": {
        "id": "JCs4xKZ2RZfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZLclVcDzkFl"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "N_EPOCHS = 10 if dgts else 50 \n",
        "\n",
        "losses = []\n",
        "for i_ep in range(N_EPOCHS):\n",
        "  shuffle_ids = np.random.choice(len(X_train), len(X_train), replace=False)\n",
        "  epoch_loss = 0\n",
        "  for i_img in trange(0, len(X_train), BATCH_SIZE):\n",
        "    batch = X_train[shuffle_ids][i_img:i_img + BATCH_SIZE]\n",
        "    epoch_loss += gen_step(batch).numpy() * len(batch)\n",
        "\n",
        "  epoch_loss /= len(X_train)\n",
        "  losses.append(epoch_loss)\n",
        "\n",
        "  opt_g.learning_rate.assign(opt_g.learning_rate * 0.99)\n",
        "\n",
        "  imgs = (gen_images(tf.zeros(shape=(25, LATENT_DIM)),\n",
        "                    tf.zeros(shape=(25, LATENT_DIM))).numpy() * 255).astype('uint8')\n",
        "  clear_output(wait=True)\n",
        "  plt.figure(figsize=(12, 7))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  if dgts:\n",
        "    plot_mn(imgs)\n",
        "  else:\n",
        "    plt.imshow(imgs.reshape((5, 5, 36, 36, 3)).transpose(0, 2, 1, 3, 4).reshape(36 * 5, 36 * 5, 3))\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(losses)\n",
        "  plt.yscale('log')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('loss')\n",
        "  plt.show()\n",
        "  print(\"Done with epoch #\", i_ep)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "I3olY4j1lb_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lltag3hx77ha"
      },
      "outputs": [],
      "source": [
        "codes = encoder.predict(X_train)\n",
        "reco = decoder.predict(codes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZktgBVrvWGS"
      },
      "outputs": [],
      "source": [
        "shuffle_ids = np.random.choice(len(X_train), len(X_train), replace=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6), dpi=100)\n",
        "if dgts:\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(X_train[shuffle_ids][:25].reshape(5, 5, 28, 28, 1).transpose((0, 2, 1, 3, 4)).reshape(5 * 28, 5 * 28));\n",
        "  plt.title('Train')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(reco[shuffle_ids][:25].reshape(5, 5, 28, 28, 1).transpose((0, 2, 1, 3, 4)).reshape(5 * 28, 5 * 28));\n",
        "  plt.title('Reconstructed');\n",
        "\n",
        "else:\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(data[shuffle_ids][:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));\n",
        "  plt.title('Train')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(reco[shuffle_ids][:25].reshape(5, 5, 36, 36, 3).transpose((0, 2, 1, 3, 4)).reshape(5 * 36, 5 * 36, 3));\n",
        "  plt.title('Reconstructed');"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if dgts:\n",
        "  z_mean, _ = encoder.predict(np.expand_dims(x_train, -1).astype(\"float32\") / 255)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_train, cmap=plt.get_cmap('jet', 10))\n",
        "  plt.colorbar()\n",
        "  plt.xlabel(\"z[0]\")\n",
        "  plt.ylabel(\"z[1]\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "E5MQJTFILFP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display a n*n 2D manifold of digits\n",
        "coord = 1.\n",
        "n = 10\n",
        "figure = np.zeros((image_size * n, image_size * n))\n",
        "# linearly spaced coordinates corresponding to the 2D plot\n",
        "# of digit classes in the latent space\n",
        "grid_x = np.linspace(-coord, coord, n)\n",
        "grid_y = np.linspace(-coord, coord, n)[::-1]\n",
        "\n",
        "for i, yi in enumerate(grid_y):\n",
        "    for j, xi in enumerate(grid_x):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(image_size, image_size)\n",
        "        figure[\n",
        "            i * image_size : (i + 1) * image_size,\n",
        "            j * image_size : (j + 1) * image_size,\n",
        "        ] = digit\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "start_range = image_size // 2\n",
        "end_range = n * image_size + start_range\n",
        "pixel_range = np.arange(start_range, end_range, image_size)\n",
        "sample_range_x = np.round(grid_x, 1)\n",
        "sample_range_y = np.round(grid_y, 1)\n",
        "plt.xticks(pixel_range, sample_range_x)\n",
        "plt.yticks(pixel_range, sample_range_y)\n",
        "plt.xlabel(\"z[0]\")\n",
        "plt.ylabel(\"z[1]\")\n",
        "plt.imshow(figure, cmap=\"Greys_r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IbfHpAXjNC91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeat the training procedure, but try to decrease the weight of the KL-loss."
      ],
      "metadata": {
        "id": "NpZZnbBJ93ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if dgts:\n",
        "  low_w_zmean, _ = encoder.predict(np.expand_dims(x_train, -1).astype(\"float32\") / 255)\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.scatter(low_w_zmean[:, 0], low_w_zmean[:, 1], c=y_train, cmap=plt.get_cmap('jet', 10))\n",
        "  plt.colorbar()\n",
        "  plt.xlabel(\"z[0]\")\n",
        "  plt.ylabel(\"z[1]\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "4Ko2zUfYWC-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PiSaHxOJKzod"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MLDM_2021_seminar12_VAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}