{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2021/blob/master/10-architectures/MLDM_2021_seminar10_AutoencodersAndSemiSupervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLFslUEjAQV-"
   },
   "source": [
    "# Autoencoder example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqjmKz_qATNL"
   },
   "source": [
    "In this example we'll show how an auto-encoder can help when labeled data is limited. Will take the MNIST data keeping only the labels of first 300 examples (out of 60000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVHvLYbQyEQs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORQkf4J0Ablq"
   },
   "source": [
    "Load and preprocess the data (as numpy arrays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91UFnB0FyaUA"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train / 255).astype('float32')\n",
    "X_test  = (X_test  / 255).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vU8aXx0iAfy1"
   },
   "source": [
    "Basic autoencoder architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = tf.keras.layers\n",
    "activation = tf.nn.relu\n",
    "\n",
    "encoder = tf.keras.Sequential([\n",
    "    ll.Reshape((1, 28, 28), input_shape=(28, 28)),\n",
    "\n",
    "    ll.Conv2D(16, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "    ll.MaxPool2D(data_format='channels_first'),\n",
    "\n",
    "    ll.Conv2D(32, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "    ll.MaxPool2D(data_format='channels_first'),\n",
    "\n",
    "    ll.Conv2D(64, 3, padding='valid', data_format='channels_first', activation=activation), \n",
    "    ll.Conv2D(128, 3, padding='valid', data_format='channels_first', activation=activation), \n",
    "    ll.Conv2D(256, 3, padding='valid', data_format='channels_first', activation=activation),\n",
    "    ll.Conv2D(32, 1, padding='same', data_format='channels_first', activation=activation),\n",
    "\n",
    "    ll.Reshape((32,))\n",
    "  ],\n",
    "  name='encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the shapes of tensors after every single layer in the encoder. (1 points)\n",
    "\n",
    "*Hint*: [A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZLrAP33y0Sx"
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.Sequential([\n",
    "    ll.Reshape((32, 1, 1), input_shape=(32,)),\n",
    "\n",
    "    ll.UpSampling2D(data_format='channels_first'), # 2x2\n",
    "    ll.Conv2D(256, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "\n",
    "    ll.UpSampling2D(data_format='channels_first'), # 4x4\n",
    "    ll.Conv2D(128, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "\n",
    "    ll.UpSampling2D(data_format='channels_first'), # 8x8\n",
    "    ll.Conv2D(64, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "\n",
    "    ll.UpSampling2D(data_format='channels_first'), # 16x16\n",
    "    ll.Conv2D(32, 3, padding='valid', data_format='channels_first', activation=activation), # 14x14\n",
    "\n",
    "    ll.UpSampling2D(data_format='channels_first'), # 28x28\n",
    "    ll.Conv2D(16, 3, padding='same', data_format='channels_first', activation=activation),\n",
    "    ll.Conv2D(1, 1, padding='valid', data_format='channels_first', activation=tf.nn.relu),\n",
    "\n",
    "    ll.Reshape((28, 28))\n",
    "  ],\n",
    "  name='decoder')\n",
    "\n",
    "encoder.save('encoder_untrained.h5')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([\n",
    "  encoder,\n",
    "  decoder\n",
    "])\n",
    "\n",
    "autoencoder.summary()\n",
    "autoencoder.compile(optimizer=tf.optimizers.Adam(learning_rate=0.003), loss=tf.keras.losses.MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmpG6LSzA-H5"
   },
   "source": [
    "Trainign it on the whole train dataset (note that `X_train` is both inputs and targets for the autoencoder, i.e. we are not using the labels `y_train`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2w81dMJ5f04"
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train, y=X_train, batch_size=256, epochs=16, validation_data=(X_test, X_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYpVWaaCBLLC"
   },
   "source": [
    "Some plotting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA72rNfw5yBw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwNCF8Mv6bmU"
   },
   "outputs": [],
   "source": [
    "plt.plot(autoencoder.history.history['loss'], label='train loss')\n",
    "plt.plot(autoencoder.history.history['val_loss'], label='test loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5vSAskFR2-Sh"
   },
   "outputs": [],
   "source": [
    "np.random.seed(23864)\n",
    "idx = np.random.randint(len(X_test), size=100)\n",
    "rec_X_test = autoencoder(X_test, training=False).numpy()\n",
    "\n",
    "def plot100(imgs):\n",
    "  plt.imshow(\n",
    "      np.array(imgs).reshape(\n",
    "          (10, 10) + imgs.shape[1:3]\n",
    "      ).transpose(0, 2, 1, 3).reshape(np.array(imgs.shape[1:]) * 10)\n",
    "  )\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.figure(figsize=(10, 5), dpi=100)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original\")\n",
    "plot100(X_test[idx])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Reconstructed\")\n",
    "plot100(rec_X_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7w_BV5sS4Lq"
   },
   "source": [
    "### Exercise: interpolating between bottleneck representations (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GTAj_i-4ap7"
   },
   "outputs": [],
   "source": [
    "digit_1 = 5\n",
    "digit_2 = 1\n",
    "\n",
    "# Let's take 10 images of digit_1 and digit_2:\n",
    "digits_1 = X_test[y_test == digit_1][:10]\n",
    "digits_2 = X_test[y_test == digit_2][:10]\n",
    "\n",
    "# Calculate the encoded representations of these digits:\n",
    "representation_1 = <YOUR CODE>\n",
    "representation_2 = <YOUR CODE>\n",
    "\n",
    "# Now create a 10x10x<BOTTLENECK_SIZE> matrix of linear interpolations between\n",
    "# the two representations:\n",
    "representation_mixed = <YOUR CODE>\n",
    "\n",
    "# Then decode the images from the mixed representations:\n",
    "mixed_imgs = <YOUR CODE>\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=100)\n",
    "plot100(mixed_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcHTdJoNUKj_"
   },
   "source": [
    "# Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75c3YT2aBN3p"
   },
   "source": [
    "Now we'll use the encoder to train a classifier on its outputs. We don't want to update the encoder's weights anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ah9prSd77tXP"
   },
   "outputs": [],
   "source": [
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NZu6dTI72Ye"
   },
   "outputs": [],
   "source": [
    "classifier = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    ll.Dense(10)\n",
    "  ],\n",
    "  name='classifier')\n",
    "\n",
    "classifier.summary()\n",
    "classifier.compile(optimizer=tf.optimizers.RMSprop(learning_rate=0.05), loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=[tf.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YU0q6A-dBawA"
   },
   "source": [
    "Now let's fit the classifier on first 300 labeled objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzJe7qVq9UEN"
   },
   "outputs": [],
   "source": [
    "classifier.fit(x=X_train[:300], y=y_train[:300], batch_size=128, epochs=50, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA5OCr-KButF"
   },
   "source": [
    "We got test accuracy up to 90% by training on just 300 objects! Note that there is 10000 objects in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uBxiqLS9lba"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(classifier.history.history['loss'], label='train')\n",
    "plt.plot(classifier.history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Cross-entropy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(classifier.history.history['sparse_categorical_accuracy'], label='train')\n",
    "plt.plot(classifier.history.history['val_sparse_categorical_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CW-XJk21B-2O"
   },
   "source": [
    "Now let's imagine we have similar architecture to train from scratch on just 300 objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JEs5ce0_mii"
   },
   "outputs": [],
   "source": [
    "encoder.trainable = True\n",
    "encoder.load_weights('encoder_untrained.h5')\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "  encoder,\n",
    "  ll.Dense(10),\n",
    "  ],\n",
    "  name='classifier')\n",
    "\n",
    "classifier.summary()\n",
    "classifier.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                   metrics=[tf.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnKHwckQAUR_"
   },
   "outputs": [],
   "source": [
    "classifier.fit(x=X_train[:300], y=y_train[:300], batch_size=64, epochs=50, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ERclRvvCWwi"
   },
   "source": [
    "This results in a heavy overfit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6k8B15e9Ajyv"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(classifier.history.history['loss'], label='train')\n",
    "plt.plot(classifier.history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Cross-entropy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(classifier.history.history['sparse_categorical_accuracy'], label='train')\n",
    "plt.plot(classifier.history.history['val_sparse_categorical_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5-oJn2BCh0H"
   },
   "source": [
    "# Simultaneously optimizing the AE and classifier\n",
    "\n",
    "Before running this code, make sure to re-initialize the autoencoder and the classifier network (run corresponding cells above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDk0sg5RFpNy"
   },
   "outputs": [],
   "source": [
    "X_train_labeled, X_train_unlabeled = X_train[:300], X_train[300:]\n",
    "y_train_labeled = y_train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQTduJu9GJyC"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSObimjOF75w"
   },
   "outputs": [],
   "source": [
    "def gen_unlabeled(batch_size):\n",
    "  ids = np.arange(len(X_train_unlabeled))\n",
    "  np.random.shuffle(ids)\n",
    "  shuffled_X_train_unlabeled = X_train_unlabeled[ids]\n",
    "  for i in range(0, len(X_train_unlabeled), batch_size):\n",
    "    yield shuffled_X_train_unlabeled[i:i+batch_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rlo13l-IG7-X"
   },
   "outputs": [],
   "source": [
    "len(X_train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTxnh5jYGo09"
   },
   "outputs": [],
   "source": [
    "unlabeled_generator = iter(cycle(gen_unlabeled(256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wr-MqV3jIcOk"
   },
   "outputs": [],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zKIGXJGyKhqa"
   },
   "outputs": [],
   "source": [
    "variables = classifier.trainable_variables + decoder.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seUHD4IFLF8x"
   },
   "outputs": [],
   "source": [
    "opt = tf.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pixdTHxVLqYO"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4q_rrngHKkA"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "LAMBDA = 0.1\n",
    "history_ae = []\n",
    "history_cl = []\n",
    "history_tot = []\n",
    "for i_epoch in range(N_EPOCHS):\n",
    "  print(\"Working on ep #\", i_epoch)\n",
    "  ids = np.arange(len(X_train_labeled))\n",
    "  np.random.shuffle(ids)\n",
    "\n",
    "  epoch_ae_loss = 0\n",
    "  epoch_cl_loss = 0\n",
    "  epoch_total_loss = 0\n",
    "\n",
    "  for i_image in range(0, len(X_train_labeled), BATCH_SIZE):\n",
    "    X_batch = X_train_labeled[ids][i_image:i_image + BATCH_SIZE]\n",
    "    y_batch = y_train_labeled[ids][i_image:i_image + BATCH_SIZE]\n",
    "    X_batch_unlabeled = next(unlabeled_generator)\n",
    "\n",
    "    with tf.GradientTape() as t:\n",
    "      reco = decoder(encoder(X_batch_unlabeled))\n",
    "      preds = classifier(X_batch)\n",
    "\n",
    "      ae_loss = tf.reduce_mean(tf.reduce_sum((X_batch_unlabeled - reco)**2, axis=(1, 2)))\n",
    "      cl_loss = tf.reduce_mean(tf.losses.sparse_categorical_crossentropy(y_batch, preds, from_logits=True))\n",
    "\n",
    "      loss = cl_loss + LAMBDA * ae_loss\n",
    "    epoch_ae_loss += ae_loss.numpy()\n",
    "    epoch_cl_loss += cl_loss.numpy()\n",
    "    epoch_total_loss += loss.numpy()\n",
    "    grads = t.gradient(loss, variables)\n",
    "    opt.apply_gradients(zip(grads, variables))\n",
    "  history_ae.append(epoch_ae_loss / len(X_train_labeled))\n",
    "  history_cl.append(epoch_cl_loss / len(X_train_labeled))\n",
    "  history_tot.append(epoch_total_loss / len(X_train_labeled))\n",
    "\n",
    "  if i_epoch % 10 == 0:\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.plot(history_ae, label='ae loss')\n",
    "    plt.plot(history_cl, label='cl loss')\n",
    "    plt.plot(history_tot, label='total')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaTmdc71NXuS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(history_ae, label='ae loss')\n",
    "plt.plot(history_cl, label='cl loss')\n",
    "plt.plot(history_tot, label='total')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRt_V_LPJoUf"
   },
   "outputs": [],
   "source": [
    "preds_train = classifier(X_train).numpy().argmax(axis=1)\n",
    "preds_test  = classifier(X_test ).numpy().argmax(axis=1)\n",
    "\n",
    "print((preds_train == y_train).mean())\n",
    "print((preds_test == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INpJR-_BSUQp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MLDM-2021-seminar10-AutoencodersAndSemiSupervised.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
